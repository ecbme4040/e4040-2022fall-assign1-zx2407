{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columbia University\n",
    "### ECBM E4040 Neural Networks and Deep Learning. Fall 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1, Task 4: Questions (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 \n",
    "What is the effect of increasing the number of layers in an MLP? Are larger (with a greater number of hidden layers) models preferred to smaller ones? If so, why? Or why not?\n",
    "\n",
    "   Your answer: **1.In the neural network, the input of the neurons in the latter layer is the weighted sum of the outputs of the former layer, and the features of the former layer are abstracted in the latter layer. The learning process is actually to adjust and optimize the weights and thresholds of each connection.The feature abstraction degree of shallow neural network is not high, and the abstraction degree of features with deeper layers is higher; 2.No.It is generally believed that increasing the number of layers can reduce the network error and improve the accuracy. But too much layers may not converge(or over-fitted),And it also depends on activation function, as well as various parameter settings.;**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 \n",
    "What is the significance of activation functions in deep learning models? Name any two activation functions that you would use for a hidden layer and for the output layer. \n",
    "\n",
    "   Your answer: **1.The biggest advantage of the activation function is that it imparts non-linearity to our models. Linear functions are straight lines or planes, thus being limited in their complexity. For most kinds of complex data, such a linear function would perform poorly and the model would be weak. So we need to use activate function get a more precise model. ; 2.Hidden layer---ReLU function; Output layer---Sigmoid function.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "Assume you have a problem to predict the annual rainfall in a certain region with some historic numeric data that was given to you, which of these 2 models (Linear Regression and Logistic Regression) would you use? \n",
    "How would you modify the problem statement to use the other model? Are they both linear? \n",
    "\n",
    "   Your answer: **1.I will use Logistic Regression.Because there are only two kinds output Rainfall or No Rainfall; 2. I will give more specific rianfall data (eg. moderate rainï¼›light rain; rainstorm) and I will use Clusting model. Both of them are not Linear Regression. **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "What is the difference between a loss function and an optimization function? \n",
    "\n",
    "   Your answer: **Loss Function used to compute the difference between the actual output and the predicted output. It is a function of internal parameters of model ( weights and bias); But in a neural network, Optimization Function is used to modify the weights and bias to minimize the error.Optimisation through  calculating the gradient,and the weights are modified in the opposite direction of the calculated gradient.This cycle is repeate to get the minima of loss function. So they are different function but related.**\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "What will happen if you choose a very small or a very large learning rate? \n",
    "\n",
    "   Your answer: **The learning rate determines how fast or slow we will move towards the optimal weights. If the learning rate is very large we will skip the optimal solution. If it is too small we will need too many iterations to converge to the best values. So using a good learning rate is crucial.**\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "What is the function of perplexity in tSNE?  \n",
    "    \n",
    "   Your answer: **The original definition of perplexity is \"expected density\", which means how many adjacent points are considered in the t-SNE optimization process, that is to say, how many elements each cluster may have. The higher the degree of prerplexity, the more t-SNE will consider. Nearby points, pay more attention to the overall situation. Therefore, higher perplexity should be used for big data, and higher perplexity can also help t-SNE get rid of the influence of noise.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
